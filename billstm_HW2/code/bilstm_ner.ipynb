{"cells":[{"cell_type":"code","source":["!pip install tensorflow==2.14.0\n","!pip install tensorflow-addons"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hYmesmeclpO9","executionInfo":{"status":"ok","timestamp":1700641796195,"user_tz":-480,"elapsed":23717,"user":{"displayName":"盧識永 LU, SHIH-YONG NE6121076","userId":"07609571125600744760"}},"outputId":"1386655f-8dfc-4a54-a481-fc75dc3e2770"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow==2.14.0 in /usr/local/lib/python3.10/dist-packages (2.14.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (23.5.26)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (0.5.4)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (3.9.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (16.0.6)\n","Requirement already satisfied: ml-dtypes==0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (0.2.0)\n","Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (1.23.5)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (23.2)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (2.3.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (4.5.0)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (0.34.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (1.59.2)\n","Requirement already satisfied: tensorboard<2.15,>=2.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (2.14.1)\n","Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (2.14.0)\n","Requirement already satisfied: keras<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (2.14.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.14.0) (0.41.3)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.5.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (2.31.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.0.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (5.3.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (2023.7.22)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (2.1.3)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.2.2)\n","Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.10/dist-packages (0.22.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (23.2)\n","Requirement already satisfied: typeguard<3.0.0,>=2.7 in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (2.13.3)\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pXbADI5q-qD4","executionInfo":{"status":"ok","timestamp":1700641803002,"user_tz":-480,"elapsed":2893,"user":{"displayName":"盧識永 LU, SHIH-YONG NE6121076","userId":"07609571125600744760"}},"outputId":"621093ee-e242-4250-8010-3a12b4b985c0"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["import os\n","os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","import tensorflow as tf\n","\n","from keras import layers\n","from keras.preprocessing.sequence import pad_sequences\n","from tensorflow_addons.layers import CRF\n","from tensorflow_addons.text.crf import crf_log_likelihood, crf_decode\n","from sklearn.metrics import classification_report\n","from sklearn.preprocessing import MultiLabelBinarizer\n","\n","# print(tf.__version__)\n","# print(tf.config.list_physical_devices(\"GPU\"))\n","tf.config.experimental.set_memory_growth(tf.config.list_physical_devices(\"GPU\")[0], True)"],"metadata":{"id":"M9JEL9ormCXl","executionInfo":{"status":"ok","timestamp":1700641814729,"user_tz":-480,"elapsed":437,"user":{"displayName":"盧識永 LU, SHIH-YONG NE6121076","userId":"07609571125600744760"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["vocabs_path = \"/content/drive/MyDrive/Colab Notebooks/Dataset/vocabs.txt\"\n","tags_path = \"/content/drive/MyDrive/Colab Notebooks/Dataset/tags.txt\"\n","train_path = \"/content/drive/MyDrive/Colab Notebooks/Dataset/train.txt\"\n","test_path = \"/content/drive/MyDrive/Colab Notebooks/Dataset/test.txt\"\n","model_path = \"/content/drive/MyDrive/Colab Notebooks/Models/bilstm/bilstm_crf_ner.ckpt\""],"metadata":{"id":"XcR63fUgmVZK","executionInfo":{"status":"ok","timestamp":1700641817435,"user_tz":-480,"elapsed":288,"user":{"displayName":"盧識永 LU, SHIH-YONG NE6121076","userId":"07609571125600744760"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["def read_dataset(file_path):\n","\n","    data_list = []\n","    label_list = []\n","    dataset = []\n","\n","    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n","        dataset = file.read().split(\"\\n\\n\")\n","\n","    dataset = [sent.split(\"\\n\") for sent in dataset]\n","    dataset = [[word for word in sent if word != \"\"] for sent in dataset]\n","    dataset = [[tuple(word.split(\"\\t\")) for word in sent] for sent in dataset]\n","    dataset = [[word for word in sent if word[0] != \"*\"] for sent in dataset]\n","\n","    for sent in dataset:\n","        try:\n","            words = [word[0] for word in sent]\n","            labels = [word[1] for word in sent]\n","            data_list.append(words)\n","            label_list.append(labels)\n","        except:\n","            print(\"Error in sentence: \")\n","            print(sent)\n","            exit(0)\n","\n","    return data_list, label_list\n","\n","\n","def get_from_txt(file_path):\n","    data = []\n","    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n","        for line in f.readlines():\n","            line = line.strip()\n","            data.append(line)\n","    return data"],"metadata":{"id":"_pVNwBa0mfz8","executionInfo":{"status":"ok","timestamp":1700641819721,"user_tz":-480,"elapsed":304,"user":{"displayName":"盧識永 LU, SHIH-YONG NE6121076","userId":"07609571125600744760"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["class BiLSTM_CRF(tf.keras.Model):\n","    def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim):\n","        \"\"\"\n","            vocab_size: vocab size\n","            tag_to_ix: tag to index\n","            embedding_dim: embedding dimension\n","            hidden_dim: hidden dimension\n","        \"\"\"\n","        super(BiLSTM_CRF, self).__init__()\n","        self.embedding_dim = embedding_dim\n","        self.hidden_dim = hidden_dim\n","        self.vocab_size = vocab_size\n","        self.tag_to_ix = tag_to_ix\n","        self.tagset_size = len(tag_to_ix)\n","\n","        # self.embedding = layers.Embedding(self.vocab_size, self.embedding_dim)\n","        self.embedding = layers.Embedding(self.vocab_size, self.embedding_dim, mask_zero=True)\n","\n","        # self.dropout = layers.Dropout(0.1)\n","        self.dropout = layers.Dropout(0.2)\n","        # self.lstm = layers.Bidirectional(layers.LSTM(self.hidden_dim // 2, return_sequences=True))\n","        self.lstm = layers.Bidirectional(layers.LSTM(self.hidden_dim // 2, return_sequences=True, recurrent_dropout=0.2))\n","\n","        self.fc = layers.Dense(self.tagset_size)\n","        self.crf = CRF(self.tagset_size)\n","\n","\n","        self.transition_params = tf.Variable(tf.random.uniform(shape=(self.tagset_size, self.tagset_size)))\n","\n","    def call(self, sentence):\n","        \"\"\"\n","            sentence: [batch_size, max_len]\n","        \"\"\"\n","        mask = tf.cast(tf.math.not_equal(sentence, 0), dtype=tf.int32)\n","        embedding = self.embedding(sentence)\n","        embedding = self.dropout(embedding)\n","        lstm = self.lstm(embedding)\n","        lstm = self.dropout(lstm)\n","        fc = self.fc(lstm)\n","        return fc\n","\n","    def loss(self, y_true, y_pred):\n","        \"\"\"\n","            y_true: [batch_size, max_len]\n","            y_pred: [batch_size, max_len, tagset_size]\n","        \"\"\"\n","        log_likelihood, self.transition_params = crf_log_likelihood(y_pred, y_true, tf.reduce_sum(tf.cast(tf.math.not_equal(y_true, 0), dtype=tf.int32), axis=1), transition_params=self.transition_params)\n","        return -tf.reduce_mean(log_likelihood)\n","\n","    def predict(self, sentence):\n","        \"\"\"\n","            sentence: [batch_size, max_len]\n","        \"\"\"\n","        mask = tf.cast(tf.math.not_equal(sentence, 0), dtype=tf.int32)\n","        embedding = self.embedding(sentence)\n","        embedding = self.dropout(embedding)\n","        lstm = self.lstm(embedding)\n","        lstm = self.dropout(lstm)\n","        fc = self.fc(lstm)\n","        viterbi_sequence, _ = crf_decode(fc, self.transition_params, tf.reduce_sum(mask, axis=1))\n","        return viterbi_sequence"],"metadata":{"id":"hES2LFKWmRJT","executionInfo":{"status":"ok","timestamp":1700641822365,"user_tz":-480,"elapsed":378,"user":{"displayName":"盧識永 LU, SHIH-YONG NE6121076","userId":"07609571125600744760"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["def data_preprocess(dataset, data2idx, max_len=100):\n","    \"\"\"\n","        dataset: [[word1, word2, ...], ...]\n","        data2idx: {word: idx, ...}\n","        max_len: max length of sentence\n","    \"\"\"\n","    dataset = [[data2idx[word] if word in data2idx else data2idx[\"[UNK]\"] for word in sentence] for sentence in dataset]\n","    dataset = pad_sequences(dataset, maxlen=max_len, padding=\"post\")\n","    dataset = tf.convert_to_tensor(dataset, dtype=tf.int32)\n","    return dataset"],"metadata":{"id":"AUi3OKblpNOI","executionInfo":{"status":"ok","timestamp":1700641826975,"user_tz":-480,"elapsed":260,"user":{"displayName":"盧識永 LU, SHIH-YONG NE6121076","userId":"07609571125600744760"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["train_data, train_label = read_dataset(train_path)\n","test_data, test_label = read_dataset(test_path)\n","\n","tags = get_from_txt(tags_path)\n","vocab = get_from_txt(vocabs_path)\n","tags = [\"[PAD]\"] + tags\n","vocab = [\"[PAD]\", \"[UNK]\"] + vocab\n","\n","tags2idx = {tag: idx for idx, tag in enumerate(tags)}\n","id2tag = {idx: tag for idx, tag in enumerate(tags)}\n","vocab2idx = {word: idx for idx, word in enumerate(vocab)}\n","id2vocab = {idx: word for idx, word in enumerate(vocab)}\n","\n","train_data = data_preprocess(train_data, vocab2idx)\n","train_label = data_preprocess(train_label, tags2idx)\n","test_data = data_preprocess(test_data, vocab2idx)\n","test_label = data_preprocess(test_label, tags2idx)\n","\n","print(train_data.shape)\n","print(train_label.shape)\n","print(test_data.shape)\n","print(test_label.shape)\n","\n","EPOCHS = 5\n","BATCH_SIZE = 64\n","BUFFER_SIZE = 1000\n","STEPS_PER_EPOCH = len(train_data) // BATCH_SIZE\n","\n","train_dataset = tf.data.Dataset.from_tensor_slices((train_data, train_label))\n","train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n","\n","test_dataset = tf.data.Dataset.from_tensor_slices((test_data, test_label))\n","test_dataset = test_dataset.batch(BATCH_SIZE, drop_remainder=True)\n","\n","model = BiLSTM_CRF(len(vocab2idx), tags2idx, 128, 128)\n","optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n","model.compile(optimizer=optimizer, loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))\n","\n","# Create a callback that saves the model's weights\n","checkpoint_path = model_path\n","checkpoint_dir = os.path.dirname(checkpoint_path)\n","\n","## uncomment below code for training\n","\n","# model_callback = tf.keras.callbacks.ModelCheckpoint(\n","#     filepath=checkpoint_path,\n","#     save_weights_only=True,\n","#     verbose=1\n","# )\n","\n","# # 创建 Early Stopping 回调\n","# early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n","\n","# # Train the model with the new callback\n","# model.fit(\n","#     train_data,\n","#     train_label,\n","#     epochs=EPOCHS,\n","#     validation_data=(test_data, test_label),\n","#     callbacks=[model_callback, early_stopping]  # 将 early_stopping 加入 callbacks 列表\n","# )\n","\n","# Load weights\n","model.load_weights(checkpoint_path).expect_partial()\n","\n","# Evaluate and classification report\n","pred = model.predict(test_data)\n","pred = pred.numpy()\n","test_label = test_label.numpy()\n","\n","tags2idx.pop(\"[PAD]\")\n","tags2idx.pop(\"O\")\n","\n","pred = [[id2tag[idx] for idx in sentence] for sentence in pred]\n","test_label = [[id2tag[idx] for idx in sentence] for sentence in test_label]\n","\n","custom_classes = list(tags2idx.keys())\n","pred = MultiLabelBinarizer(classes=custom_classes).fit_transform(pred)\n","test_label = MultiLabelBinarizer(classes=custom_classes).fit_transform(test_label)\n","\n","print(classification_report(test_label, pred, target_names=tags2idx.keys()))\n","print(\"f1-score: \", classification_report(test_label, pred, target_names=tags2idx.keys(), output_dict=True)[\"micro avg\"][\"f1-score\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zh0EXDQWoBi-","executionInfo":{"status":"ok","timestamp":1700641846568,"user_tz":-480,"elapsed":16365,"user":{"displayName":"盧識永 LU, SHIH-YONG NE6121076","userId":"07609571125600744760"}},"outputId":"05f749f2-7f3f-4da4-d153-b29e557b68f3"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"]},{"output_type":"stream","name":"stdout","text":["(50075, 100)\n","(50075, 100)\n","(14775, 100)\n","(14775, 100)\n","              precision    recall  f1-score   support\n","\n","       B-Tim       0.91      0.99      0.95      9773\n","       I-Tim       0.96      0.99      0.98      3721\n","       E-Tim       0.95      0.99      0.97     10121\n","       S-Tim       0.00      0.00      0.00         1\n","       B-Org       0.92      0.91      0.91      1468\n","       I-Org       0.69      0.54      0.61        37\n","       E-Org       0.91      0.90      0.91      1469\n","       S-Org       0.81      0.61      0.69       396\n","       B-Sym       1.00      0.99      0.99     13434\n","       I-Sym       0.97      0.98      0.97      5788\n","       E-Sym       1.00      1.00      1.00     13428\n","       S-Sym       0.96      0.86      0.90      1128\n","       B-Abb       0.99      1.00      0.99      3056\n","       I-Abb       0.99      0.93      0.96      2985\n","       E-Abb       0.99      0.95      0.97      3161\n","       S-Abb       0.00      0.00      0.00      1176\n","       B-Exa       0.99      0.98      0.98      1025\n","       I-Exa       0.98      0.99      0.99       562\n","       E-Exa       0.98      0.98      0.98      1023\n","       S-Exa       0.66      0.91      0.76        74\n","       B-Dis       0.93      0.92      0.93       468\n","       I-Dis       0.84      0.75      0.79       151\n","       E-Dis       0.93      0.90      0.91       469\n","       S-Dis       0.00      0.00      0.00         5\n","       B-Dep       0.99      0.99      0.99       776\n","       I-Dep       0.99      0.95      0.97       147\n","       E-Dep       0.99      0.99      0.99       777\n","       S-Dep       0.00      0.00      0.00         0\n","       B-Tre       0.94      0.94      0.94       109\n","       I-Tre       0.00      0.00      0.00         2\n","       E-Tre       0.87      0.92      0.89       110\n","       S-Tre       0.00      0.00      0.00         0\n","       B-Med       0.96      0.94      0.95       139\n","       I-Med       0.94      0.99      0.96       135\n","       E-Med       0.96      0.92      0.94       139\n","       S-Med       0.00      0.00      0.00         0\n","       B-Hea       1.00      0.75      0.86         8\n","       I-Hea       0.00      0.00      0.00         0\n","       E-Hea       1.00      0.62      0.77         8\n","       S-Hea       0.00      0.00      0.00         0\n","\n","   micro avg       0.97      0.96      0.97     77269\n","   macro avg       0.72      0.70      0.71     77269\n","weighted avg       0.95      0.96      0.96     77269\n"," samples avg       0.96      0.96      0.96     77269\n","\n","f1-score:  0.965411351606989\n"]}]},{"cell_type":"code","source":["sentence_original = \"昨天開始全身起紅疹。\"\n","sentence = sentence_original\n","sentence = [vocab2idx[word] if word in vocab2idx else vocab2idx[\"[UNK]\"] for word in sentence]\n","sentence = pad_sequences([sentence], maxlen=100, padding=\"post\")\n","sentence = tf.convert_to_tensor(sentence, dtype=tf.int32)\n","pred = model.predict(sentence)\n","pred = pred.numpy()\n","pred = [id2tag[idx] for idx in pred[0]]\n","pred = pred[:len(sentence_original)]\n","print(pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4Ap8AxKZpabm","executionInfo":{"status":"ok","timestamp":1700643102709,"user_tz":-480,"elapsed":3708,"user":{"displayName":"盧識永 LU, SHIH-YONG NE6121076","userId":"07609571125600744760"}},"outputId":"c2fadadb-866b-4156-c550-acefb8b94bff"},"execution_count":58,"outputs":[{"output_type":"stream","name":"stdout","text":["['B-Tim', 'E-Tim', 'O', 'O', 'B-Org', 'E-Org', 'O', 'B-Sym', 'E-Sym', 'O']\n"]}]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.6"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}