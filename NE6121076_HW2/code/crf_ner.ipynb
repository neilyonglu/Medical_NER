{"cells":[{"cell_type":"code","source":["!pip install python-crfsuite\n","!pip install scikit-learn\n","!pip install nltk gensim"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CLRQq9qL0VYX","executionInfo":{"status":"ok","timestamp":1700640583167,"user_tz":-480,"elapsed":21140,"user":{"displayName":"盧識永 LU, SHIH-YONG NE6121076","userId":"07609571125600744760"}},"outputId":"c12b20e6-9774-4716-dda5-860e6fe2cef7"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting python-crfsuite\n","  Downloading python_crfsuite-0.9.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (993 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/993.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/993.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m952.3/993.5 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m993.5/993.5 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: python-crfsuite\n","Successfully installed python-crfsuite-0.9.9\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.23.5)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.3)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n","Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.23.5)\n","Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.3)\n","Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n"]}]},{"cell_type":"code","source":["import pycrfsuite\n","\n","from google.colab import drive\n","drive.mount(\"/content/drive\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pXbADI5q-qD4","executionInfo":{"status":"ok","timestamp":1700640605146,"user_tz":-480,"elapsed":19225,"user":{"displayName":"盧識永 LU, SHIH-YONG NE6121076","userId":"07609571125600744760"}},"outputId":"b87879e3-da50-4f45-e0b7-7f68a322a895"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["train_path = \"/content/drive/MyDrive/Colab Notebooks/Dataset/train.txt\"\n","test_path = \"/content/drive/MyDrive/Colab Notebooks/Dataset/test.txt\"\n","tags_path = \"/content/drive/MyDrive/Colab Notebooks/Dataset/tags.txt\"\n","model_path = \"/content/drive/MyDrive/Colab Notebooks/Models/crf/ner.crfsuite\""],"metadata":{"id":"y2WfQOBDg6_C","executionInfo":{"status":"ok","timestamp":1700640608590,"user_tz":-480,"elapsed":301,"user":{"displayName":"盧識永 LU, SHIH-YONG NE6121076","userId":"07609571125600744760"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["def read_dataset(file_path):\n","\n","    data_list = []\n","    label_list = []\n","    dataset = []\n","\n","    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n","        dataset = file.read().split(\"\\n\\n\")\n","\n","    dataset = [sent.split(\"\\n\") for sent in dataset]\n","    dataset = [[word for word in sent if word != \"\"] for sent in dataset]\n","    dataset = [[tuple(word.split(\"\\t\")) for word in sent] for sent in dataset]\n","    dataset = [[word for word in sent if word[0] != \"*\"] for sent in dataset]\n","\n","    for sent in dataset:\n","        try:\n","            words = [word[0] for word in sent]\n","            labels = [word[1] for word in sent]\n","            data_list.append(words)\n","            label_list.append(labels)\n","        except:\n","            print(\"Error in sentence: \")\n","            print(sent)\n","            exit(0)\n","\n","    return data_list, label_list\n","\n","\n","def get_from_txt(file_path):\n","    data = []\n","    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n","        for line in f.readlines():\n","            line = line.strip()\n","            data.append(line)\n","    return data"],"metadata":{"id":"34uE2RzSi8wg","executionInfo":{"status":"ok","timestamp":1700640610995,"user_tz":-480,"elapsed":2,"user":{"displayName":"盧識永 LU, SHIH-YONG NE6121076","userId":"07609571125600744760"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["import pycrfsuite\n","import warnings\n","import nltk\n","from gensim.models import Word2Vec\n","from nltk.tokenize import word_tokenize\n","\n","warnings.filterwarnings(\"ignore\")\n","nltk.download('averaged_perceptron_tagger')\n","\n","from sklearn.metrics import classification_report\n","from sklearn.preprocessing import MultiLabelBinarizer\n","\n","\n","class CRFNER:\n","    def __init__(self, model_path=None):\n","        self.model_path = model_path\n","        self.model = pycrfsuite.Trainer(verbose=False)\n","        self.model.set_params({\n","            \"c1\": 1.0,\n","            \"c2\": 1e-3,\n","            \"max_iterations\": 100,\n","            \"feature.possible_transitions\": True\n","        })\n","        self.tagger = None\n","\n","    def train(self, train_data, train_label):\n","        for xseq, yseq in zip(train_data, train_label):\n","            sent_features = [self.word2features(xseq, i) for i in range(len(xseq))]\n","            self.model.append(sent_features, yseq)\n","        self.model.train(self.model_path)\n","\n","    def word2features(self, sent, i):\n","        word = sent[i][0]\n","        prev_word = \"<s>\" if i == 0 else sent[i-1][0]\n","        next_word = \"</s>\" if i == len(sent)-1 else sent[i+1][0]\n","\n","        # 特徵字典\n","        features = {\n","            \"word\": word,\n","            \"prev_word\": prev_word,\n","            \"next_word\": next_word,\n","            \"word+prev_word\": word + prev_word,\n","            \"word+next_word\": word + next_word,\n","            \"is_first\": i == 0,\n","            \"is_last\": i == len(sent) - 1,\n","            \"is_numeric\": word.isdigit(),\n","            \"is_alpha\": word.isalpha(),\n","            \"pos_tag\": self.get_pos_tag(word),  # 加入詞性標籤作為特徵\n","        }\n","\n","        return features\n","\n","    def get_pos_tag(self, word):\n","        \"\"\"\n","        獲取給定詞的詞性標籤\n","        \"\"\"\n","        pos_tags = nltk.pos_tag([word])\n","        return pos_tags[0][1]\n","\n","    def load_model(self):\n","        self.tagger = pycrfsuite.Tagger()\n","        self.tagger.open(self.model_path)\n","\n","    def predict(self, sent):\n","        if self.tagger is None:\n","            self.load_model()\n","        sent = list(sent)\n","        sent_features = [self.word2features(sent, i) for i in range(len(sent))]\n","        labels = self.tagger.tag(sent_features)\n","        return labels\n","\n","    def evaluate(self, test_data, test_label, tags2idx):\n","\n","        if self.tagger is None:\n","            self.load_model()\n","\n","        # remove [PAD] and O tags\n","        tags2idx.pop(\"[PAD]\")\n","        tags2idx.pop(\"O\")\n","\n","        custom_classes = list(tags2idx.keys())\n","        pred = [self.predict(sent) for sent in test_data]\n","        pred = MultiLabelBinarizer(classes=custom_classes).fit_transform(pred)\n","        test_label = MultiLabelBinarizer(classes=custom_classes).fit_transform(test_label)\n","\n","        print(classification_report(test_label, pred, target_names=tags2idx.keys()))\n","        print(\"f1-score: \", classification_report(test_label, pred, target_names=tags2idx.keys(), output_dict=True)[\"micro avg\"][\"f1-score\"])\n","\n","    def train(self, train_data, train_label):\n","        for xseq, yseq in zip(train_data, train_label):\n","            sent_features = [self.word2features(xseq, i) for i in range(len(xseq))]\n","            self.model.append(sent_features, yseq)\n","        self.model.train(self.model_path)\n","\n","    def word2features(self, sent, i):\n","        \"\"\"\n","            Extract features from a single word\n","            sent: a list of words\n","            i: index of the word\n","        \"\"\"\n","        word = sent[i][0]\n","        prev_word = \"<s>\" if i == 0 else sent[i-1][0]\n","        next_word = \"</s>\" if i == len(sent)-1 else sent[i+1][0]\n","\n","        pos_tag = self.get_pos_tag(word)\n","\n","        features = {\n","            \"word\": word,\n","            \"prev_word\": prev_word,\n","            \"next_word\": next_word,\n","            \"word+prev_word\": word + prev_word,\n","            \"word+next_word\": word + next_word,\n","            \"is_first\": i == 0,\n","            \"is_last\": i == len(sent) - 1,\n","            \"is_numeric\": word.isdigit(),\n","            \"is_alpha\": word.isalpha(),\n","            \"pos_tag\": pos_tag,  # 新增詞性標籤作為特徵\n","        }\n","\n","        return features"],"metadata":{"id":"yIlWG6GYiS9Q","executionInfo":{"status":"ok","timestamp":1700640617651,"user_tz":-480,"elapsed":3910,"user":{"displayName":"盧識永 LU, SHIH-YONG NE6121076","userId":"07609571125600744760"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6adc17ad-dd97-4892-933f-3f9c3bc132c3"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"]}]},{"cell_type":"code","source":["train_data, train_label = read_dataset(train_path)\n","test_data, test_label = read_dataset(test_path)\n","\n","print(len(train_data))\n","print(len(train_label))\n","print(len(test_data))\n","print(len(test_label))\n","\n","tags = get_from_txt(tags_path)\n","tags = [\"[PAD]\"] + tags\n","tags2idx = {tag: idx for idx, tag in enumerate(tags)}\n","\n","ner = CRFNER(model_path)\n","# ner.train(train_data, train_label)\n","ner.evaluate(test_data, test_label, tags2idx)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wEPh7ImbieNv","executionInfo":{"status":"ok","timestamp":1700640759360,"user_tz":-480,"elapsed":63577,"user":{"displayName":"盧識永 LU, SHIH-YONG NE6121076","userId":"07609571125600744760"}},"outputId":"eb97dead-eb19-42f3-af7f-16762819a568"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["50075\n","50075\n","14775\n","14775\n","              precision    recall  f1-score   support\n","\n","       B-Tim       0.93      1.00      0.97      9773\n","       I-Tim       0.97      1.00      0.99      3721\n","       E-Tim       0.97      1.00      0.98     10121\n","       S-Tim       0.00      0.00      0.00         1\n","       B-Org       0.93      0.96      0.94      1468\n","       I-Org       0.85      0.92      0.88        37\n","       E-Org       0.93      0.96      0.94      1469\n","       S-Org       0.83      0.68      0.75       396\n","       B-Sym       1.00      1.00      1.00     13434\n","       I-Sym       0.99      0.98      0.98      5788\n","       E-Sym       1.00      1.00      1.00     13428\n","       S-Sym       0.96      0.88      0.92      1128\n","       B-Abb       0.99      1.00      1.00      3056\n","       I-Abb       0.99      0.94      0.96      2985\n","       E-Abb       0.99      0.97      0.98      3161\n","       S-Abb       0.00      0.00      0.00      1176\n","       B-Exa       0.99      0.99      0.99      1025\n","       I-Exa       0.99      0.99      0.99       562\n","       E-Exa       0.99      0.99      0.99      1023\n","       S-Exa       0.82      0.88      0.85        74\n","       B-Dis       0.96      0.93      0.94       468\n","       I-Dis       0.91      0.87      0.89       151\n","       E-Dis       0.96      0.93      0.95       469\n","       S-Dis       0.00      0.00      0.00         5\n","       B-Dep       0.99      0.99      0.99       776\n","       I-Dep       0.98      0.97      0.97       147\n","       E-Dep       0.99      0.99      0.99       777\n","       S-Dep       0.00      0.00      0.00         0\n","       B-Tre       0.99      0.95      0.97       109\n","       I-Tre       0.17      0.50      0.25         2\n","       E-Tre       1.00      0.95      0.98       110\n","       S-Tre       0.00      0.00      0.00         0\n","       B-Med       0.98      0.94      0.96       139\n","       I-Med       0.98      0.96      0.97       135\n","       E-Med       0.98      0.94      0.96       139\n","       S-Med       0.00      0.00      0.00         0\n","       B-Hea       1.00      0.38      0.55         8\n","       I-Hea       0.00      0.00      0.00         0\n","       E-Hea       1.00      0.38      0.55         8\n","       S-Hea       0.00      0.00      0.00         0\n","\n","   micro avg       0.98      0.97      0.97     77269\n","   macro avg       0.75      0.72      0.73     77269\n","weighted avg       0.96      0.97      0.97     77269\n"," samples avg       0.97      0.96      0.96     77269\n","\n","f1-score:  0.9737975102764412\n"]}]},{"cell_type":"code","source":["# test\n","sent = \"昨天開始全身起紅疹。\"\n","print(ner.predict(sent))"],"metadata":{"id":"QDoqdfWXq6bG","executionInfo":{"status":"ok","timestamp":1700641645954,"user_tz":-480,"elapsed":317,"user":{"displayName":"盧識永 LU, SHIH-YONG NE6121076","userId":"07609571125600744760"}},"outputId":"df8a8509-891f-4ce0-c5cd-b8d2e1fc1d17","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["['B-Tim', 'E-Tim', 'O', 'O', 'B-Org', 'E-Org', 'O', 'B-Sym', 'E-Sym', 'O']\n"]}]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.6"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}